_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 100)               0         
_________________________________________________________________
dense (Dense)                (None, 180)               18180     
_________________________________________________________________
dropout (Dropout)            (None, 180)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 180)               32580     
_________________________________________________________________
dropout_1 (Dropout)          (None, 180)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 180)               32580     
_________________________________________________________________
dropout_2 (Dropout)          (None, 180)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 100)               18100     
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 30)                3030      
_________________________________________________________________
dropout_4 (Dropout)          (None, 30)                0         
_________________________________________________________________
dense_5 (Dense)              (None, 4)                 124       
=================================================================
Total params: 104,594
Trainable params: 104,594
Non-trainable params: 0
_________________________________________________________________
Iteration:  1
Train on 95499 samples, validate on 4000 samples
Epoch 1/80
 - 18s - loss: 1.3890 - acc: 0.2590 - val_loss: 1.3862 - val_acc: 0.2605
Epoch 2/80
 - 11s - loss: 1.3850 - acc: 0.2658 - val_loss: 1.3856 - val_acc: 0.2603
Epoch 3/80
 - 11s - loss: 1.3803 - acc: 0.2761 - val_loss: 1.3672 - val_acc: 0.3150
Epoch 4/80
 - 12s - loss: 1.3731 - acc: 0.2914 - val_loss: 1.3637 - val_acc: 0.3103
Epoch 5/80

Epoch 00005: saving model to model/run16/
 - 11s - loss: 1.3725 - acc: 0.2956 - val_loss: 1.3637 - val_acc: 0.3200
Epoch 6/80
 - 12s - loss: 1.3718 - acc: 0.2950 - val_loss: 1.3653 - val_acc: 0.3165
Epoch 7/80
 - 11s - loss: 1.3711 - acc: 0.2962 - val_loss: 1.3635 - val_acc: 0.3173
Epoch 8/80
 - 11s - loss: 1.3702 - acc: 0.2979 - val_loss: 1.3620 - val_acc: 0.3117
Epoch 9/80
 - 11s - loss: 1.3698 - acc: 0.2992 - val_loss: 1.3626 - val_acc: 0.3183
Epoch 10/80

Epoch 00010: saving model to model/run16/
 - 11s - loss: 1.3691 - acc: 0.3010 - val_loss: 1.3643 - val_acc: 0.3147
Epoch 11/80
 - 11s - loss: 1.3687 - acc: 0.3008 - val_loss: 1.3594 - val_acc: 0.3135
Epoch 12/80
 - 11s - loss: 1.3680 - acc: 0.2997 - val_loss: 1.3589 - val_acc: 0.3180
Epoch 13/80
 - 11s - loss: 1.3673 - acc: 0.3028 - val_loss: 1.3653 - val_acc: 0.3220
Epoch 14/80
 - 11s - loss: 1.3675 - acc: 0.3033 - val_loss: 1.3623 - val_acc: 0.3027
Epoch 15/80

Epoch 00015: saving model to model/run16/
 - 11s - loss: 1.3669 - acc: 0.3037 - val_loss: 1.3569 - val_acc: 0.3142
Epoch 16/80
 - 11s - loss: 1.3666 - acc: 0.3067 - val_loss: 1.3614 - val_acc: 0.3232
Epoch 17/80
 - 11s - loss: 1.3657 - acc: 0.3100 - val_loss: 1.3608 - val_acc: 0.3260
Epoch 18/80
 - 11s - loss: 1.3642 - acc: 0.3134 - val_loss: 1.3560 - val_acc: 0.3307
Epoch 19/80
 - 11s - loss: 1.3640 - acc: 0.3144 - val_loss: 1.3528 - val_acc: 0.3335
Epoch 20/80

Epoch 00020: saving model to model/run16/
 - 11s - loss: 1.3582 - acc: 0.3253 - val_loss: 1.3430 - val_acc: 0.3470
Epoch 21/80
 - 11s - loss: 1.3526 - acc: 0.3322 - val_loss: 1.3361 - val_acc: 0.3573
Epoch 22/80
 - 11s - loss: 1.3508 - acc: 0.3338 - val_loss: 1.3440 - val_acc: 0.3318
Epoch 23/80
 - 11s - loss: 1.3494 - acc: 0.3344 - val_loss: 1.3337 - val_acc: 0.3438
Epoch 24/80
 - 11s - loss: 1.3485 - acc: 0.3351 - val_loss: 1.3436 - val_acc: 0.3442
Epoch 25/80

Epoch 00025: saving model to model/run16/
 - 11s - loss: 1.3465 - acc: 0.3370 - val_loss: 1.3291 - val_acc: 0.3480
Epoch 26/80
 - 11s - loss: 1.3451 - acc: 0.3371 - val_loss: 1.3281 - val_acc: 0.3535
Epoch 27/80
 - 11s - loss: 1.3441 - acc: 0.3375 - val_loss: 1.3237 - val_acc: 0.3595
Epoch 28/80
 - 11s - loss: 1.3433 - acc: 0.3391 - val_loss: 1.3294 - val_acc: 0.3560
Epoch 29/80
 - 11s - loss: 1.3427 - acc: 0.3385 - val_loss: 1.3333 - val_acc: 0.3503
Epoch 30/80

Epoch 00030: saving model to model/run16/
 - 11s - loss: 1.3427 - acc: 0.3386 - val_loss: 1.3331 - val_acc: 0.3573
Epoch 31/80
 - 11s - loss: 1.3422 - acc: 0.3378 - val_loss: 1.3254 - val_acc: 0.3555
Epoch 32/80
 - 11s - loss: 1.3409 - acc: 0.3390 - val_loss: 1.3239 - val_acc: 0.3560
Epoch 33/80
 - 11s - loss: 1.3407 - acc: 0.3385 - val_loss: 1.3199 - val_acc: 0.3600
Epoch 34/80
 - 11s - loss: 1.3391 - acc: 0.3412 - val_loss: 1.3331 - val_acc: 0.3577
Epoch 35/80

Epoch 00035: saving model to model/run16/
 - 13s - loss: 1.3390 - acc: 0.3417 - val_loss: 1.3201 - val_acc: 0.3565
Epoch 36/80
 - 12s - loss: 1.3380 - acc: 0.3399 - val_loss: 1.3240 - val_acc: 0.3647
Epoch 37/80
 - 12s - loss: 1.3375 - acc: 0.3410 - val_loss: 1.3194 - val_acc: 0.3582
Epoch 38/80
 - 12s - loss: 1.3369 - acc: 0.3410 - val_loss: 1.3206 - val_acc: 0.3587
Epoch 39/80
